{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-GAN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoFwmEm1X96Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdlMVL8GX_Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_init(in_shape):\n",
        "  val = tf.random_normal(shape = in_shape, stddev = 1./tf.sqrt(in_shape[0]/2.))\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhmYpAZAMgDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.002\n",
        "batch_size = 32\n",
        "epochs = 100000\n",
        "Z_dim = 64\n",
        "image_dimension = 784\n",
        "\n",
        "D_H1 = 256\n",
        "G_H1 = 256\n",
        "E_H1 = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZbHfbs8YDOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Disc_W = {\"disc_H\" : tf.Variable(xavier_init([image_dimension + Z_dim, D_H1])),\n",
        "          \"disc_final\" : tf.Variable(xavier_init([D_H1, 1]))\n",
        "          }\n",
        "\n",
        "Disc_Bias = {\"disc_H\" : tf.Variable(xavier_init([D_H1])),\n",
        "          \"disc_final\" : tf.Variable(xavier_init([1]))\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSlHaKUaYHf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Gen_W = {\"Gen_H\" : tf.Variable(xavier_init([Z_dim, G_H1])),\n",
        "          \"Gen_final\" : tf.Variable(xavier_init([G_H1, image_dimension]))\n",
        "          }\n",
        "\n",
        "Gen_Bias = {\"Gen_H\" : tf.Variable(xavier_init([G_H1])),\n",
        "          \"Gen_final\" : tf.Variable(xavier_init([image_dimension]))\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7mI7YNIYHWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "E_W = {\"E_H\" : tf.Variable(xavier_init([image_dimension, E_H1])),\n",
        "          \"E_final\" : tf.Variable(xavier_init([E_H1, Z_dim]))\n",
        "          }\n",
        "\n",
        "E_Bias = {\"E_H\" : tf.Variable(xavier_init([E_H1])),\n",
        "          \"E_final\" : tf.Variable(xavier_init([Z_dim]))\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1aJqWHsNchG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape = [None, image_dimension])\n",
        "Z = tf.placeholder(tf.float32, shape = [None, Z_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfZJ3L6YNgvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Z_distribution(m, n):\n",
        "  return np.random.uniform(-1., 1., size = [m, n])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN4HmXcPNiN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator(z):  \n",
        "  G_hidden_layer = tf.nn.relu(tf.add(tf.matmul(z, Gen_W['Gen_H']), Gen_Bias['Gen_H']))\n",
        "  gen_output = tf.add(tf.matmul(G_hidden_layer, Gen_W['Gen_final']), Gen_Bias['Gen_final'])\n",
        "  gen_prob_output = tf.nn.sigmoid(gen_output)\n",
        "  return gen_prob_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0zPLKcNjBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Discriminator(x,z):\n",
        "  input = tf.concat(axis = 1, values = [x, z])  \n",
        "  D_hidden_layer = tf.nn.relu(tf.add(tf.matmul(input, Disc_W['disc_H']), Disc_Bias['disc_H']))\n",
        "  disc_output = tf.add(tf.matmul(D_hidden_layer, Disc_W['disc_final']), Disc_Bias['disc_final'])\n",
        "  disc_prob_output = tf.nn.sigmoid(disc_output)\n",
        "  return disc_prob_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSuXQEdWNi-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Encoder_NN(x):\n",
        "  Q_hidden_layer = tf.nn.relu(tf.add(tf.matmul(x, Q_W['Q_H']), Q_Bias['Q_H']))\n",
        "  Q_output = tf.add(tf.matmul(Q_hidden_layer, Q_W['Q_final']), Q_Bias['Q_final'])\n",
        "  Q_prob_output = (Q_output)\n",
        "  return Q_prob_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwwF2jj5OOXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_generated = Encoder_NN(X)\n",
        "x_generated = Generator(Z)\n",
        "\n",
        "real_output_Disc = Discriminator(X, z_generated)\n",
        "fake_output_Disc = Discriminator(x_generated, Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJn_ImYWOORd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Disc_Loss = -tf.reduce_mean(tf.log(real_output_Disc + 1e-7) + tf.log(1.0 - fake_output_Disc + 1e-7))\n",
        "Gen_Loss = -tf.reduce_mean(tf.log(fake_output_Disc + 1e-7) + tf.log(1.0 - real_output_Disc + 1e-7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaYjIAWWNi5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Disc_params = [Disc_W['disc_H'], Disc_W['disc_final'], Disc_Bias['disc_H'], Disc_Bias['disc_final']]\n",
        "Gen_params = [Gen_W['Gen_H'], Gen_W['Gen_final'], Gen_Bias['Gen_H'], Gen_Bias['Gen_final']]\n",
        "E_params = [E_W['E_H'], E_W['E_final'], E_Bias['E_H'], E_Bias['E_final']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtSWYR4TNitu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_optimize = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(Gen_Loss, var_list = Gen_params + E_params)\n",
        "Disc_optimize = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(Disc_Loss, var_list = Disc_params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx5ofShrNiqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "  z_noise = Z_distribution(batch_size, Z_dim)\n",
        "\n",
        "  _, Disc_loss_epoch = sess.run([Disc_optimize, Disc_Loss], feed_dict = {X:X_batch, Z:z_noise})\n",
        "  _, Gen_loss_epoch = sess.run([gen_optimize, Gen_Loss], feed_dict = {X:X_batch, Z:z_noise})\n",
        "\n",
        "\n",
        "  if epoch%2000 == 0:\n",
        "    print('Steps: {0}, Disc Loss: {1}, Generator Loss: {2}'.format(epoch, Disc_loss_epoch, Gen_loss_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DexSkMlIPfwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_output , _ = Generator(Z)\n",
        "n = 6\n",
        "canvas = np.empty((28*n, 28*n))\n",
        "\n",
        "for i in range(n):\n",
        "  Z_noise = Z_distribution(batch_size, Z_dim)\n",
        "\n",
        "  generated_image  = sess.run(test_output, feed_dict = {Z:Z_noise})\n",
        "  for j in range(n):\n",
        "    canvas[i * 28: (i+1) * 28, j * 28: (j+1) * 28] = generated_image[j].reshape([28, 28])\n",
        "\n",
        "\n",
        "plt.figure(figsize = (n, n))\n",
        "plt.imshow(canvas, origin = \"upper\", cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfBCBk9FPfrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Validation that the enc and the decoder are inverse of each other, by passing one sample through the whole cycle\n",
        "\n",
        "z_generated = Encoder_NN(X)\n",
        "test_output = Generator(z_generated)\n",
        "n = 6\n",
        "canvas1 = np.empty((28*n, 28*n))\n",
        "canvas2 = np.empty((28*n, 28*n))\n",
        "\n",
        "for i in range(n):\n",
        "  X_batch, _ = mnist.train.next_batch(batch_size)\n",
        "\n",
        "  generated_image  = sess.run(test_output, feed_dict = {X:X_batch})\n",
        "  for j in range(n):\n",
        "    canvas2[i * 28: (i+1) * 28, j * 28: (j+1) * 28] = generated_image[j].reshape([28, 28])\n",
        "\n",
        "  for j in range(n):\n",
        "    canvas1[i * 28: (i+1) * 28, j * 28: (j+1) * 28] = X_batch[j].reshape([28, 28])\n",
        "\n",
        "\n",
        "f, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(canvas1, origin = \"upper\", cmap = 'gray')\n",
        "ax[1].imshow(canvas2, origin = \"upper\", cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}