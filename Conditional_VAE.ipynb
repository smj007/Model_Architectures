{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditional - VAE",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipCjkNdCkcSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVYNpjIw7-JP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe524a1f-cfe2-4a3c-8683-bf6ac1247bcb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDIYm1EH7_xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "database = input_data.read_data_sets('/content/data', one_hot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TboyKxVR8BTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "epochs = 60000\n",
        "labels = 10\n",
        "batch_size = 32\n",
        "image_dimension = 784\n",
        "neural_network_dimension = 512 #for the hidden layer\n",
        "latent_variable_dimension = 2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCC1NmRz8Dj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier(in_shape):\n",
        "  val = tf.random_normal(shape = in_shape, stddev = 1./tf.sqrt(in_shape[0]/2.))\n",
        "  return val"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N94FTQjp8FNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #weight dict\n",
        "\n",
        " Weight = {\n",
        "     \"weight_matrix_encoder_hidden\": tf.Variable(xavier([image_dimension, neural_network_dimension])),\n",
        "     \"weight_mean_hidden\": tf.Variable(xavier([neural_network_dimension, latent_variable_dimension])),\n",
        "     \"weight_std_hidden\": tf.Variable(xavier([neural_network_dimension, latent_variable_dimension])),\n",
        "     \"weight_matrix_decoder_hidden\": tf.Variable(xavier([latent_variable_dimension, neural_network_dimension])),\n",
        "     \"weight_decoder\": tf.Variable(xavier([neural_network_dimension, image_dimension]))\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWlMBzk38IMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Bias = {\n",
        "     \"bias_matrix_encoder_hidden\": tf.Variable(xavier([neural_network_dimension])),\n",
        "     \"bias_mean_hidden\": tf.Variable(xavier([latent_variable_dimension])),\n",
        "     \"bias_std_hidden\": tf.Variable(xavier([latent_variable_dimension])),\n",
        "     \"bias_matrix_decoder_hidden\": tf.Variable(xavier([neural_network_dimension])),\n",
        "     \"bias_decoder\": tf.Variable(xavier([image_dimension]))\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9apacfN08I6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#computational graph\n",
        "\n",
        "#Encoder\n",
        "\n",
        "image_X = tf.placeholder(tf.float32, shape = [None, image_dimension])\n",
        "label_X = tf.placeholder(tf.float32, shape = [None, image_dimension])\n",
        "\n",
        "input_image = tf.concat(axis = 1, values = [image_X, label_X])   #shape is of [None, 784+10]\n",
        "print(input_image.shape)\n",
        "\n",
        "Encoder_layer = tf.add(tf.matmul(input_image, Weight['weight_matrix_encoder_hidden']), Bias['bias_matrix_encoder_hidden'])\n",
        "Encoder_layer = tf.nn.tanh(Encoder_layer)\n",
        "\n",
        "Mean_layer = tf.add(tf.matmul(Encoder_layer, Weight['weight_mean_hidden']), Bias['bias_mean_hidden'])\n",
        "Standard_deviation_layer = tf.add(tf.matmul(Encoder_layer, Weight['weight_std_hidden']), Bias['bias_std_hidden']) \n",
        "\n",
        "\n",
        "epsilon = tf.random_normal(tf.shape(Standard_deviation_layer), dtype = tf.float32, mean = 0.0, stddev = 1.0)\n",
        "latent_layer = Mean_layer + tf.exp(0.5 * Standard_deviation_layer) * epsilon  #this is a numerical stability move\n",
        "\n",
        "modified_layer = tf.concat(axis = 1, values = [latent_layer, label_X])\n",
        "Decoder_hidden = tf.add(tf.matmul(latent_layer, Weight['weight_matrix_decoder_hidden']), Bias['bias_matrix_decoder_hidden'])\n",
        "Decoder_hidden = tf.nn.tanh(Decoder_hidden)\n",
        "\n",
        "Decoder_output_layer = tf.add(tf.matmul(Decoder_hidden, Weight['weight_decoder']), Bias['bias_decoder'])\n",
        "Decoder_output_layer = tf.nn.sigmoid(Decoder_output_layer)\n",
        "\n",
        "print(Decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdCwok4p8LlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def loss_function(reconstructed_image, Y):\n",
        "\n",
        "   data_fidelity_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = reconstructed_image, labels = Y)\n",
        "   data_fidelity_loss = tf.reduce_sum(data_fidelity_loss, 1)\n",
        "\n",
        "   KL_div_loss = 1 + Standard_deviation_layer - tf.square(Mean_layer) - tf.exp(Standard_deviation_layer)\n",
        "   KL_div_loss = -0.5 * tf.reduce_sum(KL_div_loss, 1)\n",
        "\n",
        "   #weight for each case possible\n",
        "   alpha = 1\n",
        "   beta = 1\n",
        "   network_loss = tf.reduce_mean(alpha * data_fidelity_loss + beta * KL_div_loss)\n",
        "   return network_loss\n",
        "\n",
        " loss_value = loss_function(image_X, Decoder_output_layer)\n",
        " optimizer = tf.train.RMSPropOptimizer(lr).minimize(loss_value)\n",
        "\n",
        " init = tf.global_variables_initializer()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHHSmEyu8NnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range(epochs):\n",
        "  x_batch, x_label = database.train.next_batch(batch_size)\n",
        "  _, loss = sess.run([optimizer, loss_value], feed_dict = {image_X : x_batch, label_X : x_label})\n",
        "  if i%5000 == 0:\n",
        "    print('Loss is {0} at iteration {1}'.format(loss, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIWssfIr8RGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing phase - test only generator to sample the data from the distn but a new sample\n",
        "\n",
        "noise_X = tf.placeholder(tf.float32, shape = [None, latent_variable_dimension])\n",
        "\n",
        " #generative model testing\n",
        "\n",
        "modified_input = tf.concat(axis = 1, values = [noise_X, label_X])\n",
        "Decoder_hidden = tf.add(tf.matmul(modified_input, Weight['weight_matrix_decoder_hidden']), Bias['bias_matrix_decoder_hidden'])\n",
        "Decoder_hidden = tf.nn.tanh(Decoder_hidden)\n",
        "\n",
        "Decoder_output_layer = tf.add(tf.matmul(Decoder_hidden, Weight['weight_decoder']), Bias['bias_decoder'])\n",
        "Decoder_output_layer = tf.nn.sigmoid(Decoder_output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd1wM8Ps8Rt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualising the output obtained ----\n",
        "\n",
        "n = 20 #the grid dim\n",
        "x_limit = np.linspace(-2, 2, n)\n",
        "y_limit = np.linspace(-2, 2, n)\n",
        "empty_image = np.empty((28*n, 28*n))\n",
        "\n",
        "x_custom_label = np.array([[0,0,0,0,0,0,0,0,1,0]] * batch_size) #change the OHE vector acc to which digit u want to generate\n",
        "\n",
        "for i, zi in enumerate(x_limit):\n",
        "  for j, pi in enumerate(y_limit):\n",
        "    #generated_latent_layer = np.array([[zi, pi]]*batch_size) #images fed as input\n",
        "    generated_latent_layer = np.random.normal(0, 1, size = [batch_size, latent_variable_dimension])\n",
        "    generated_image  = sess.run(Decoder_output_layer, feed_dict = {noise_X : generated_latent_layer, label_X : x_custom_label})\n",
        "    empty_image[(n-1-i)*28 : (n-i)*28, j*28 : (j+1)*28] = generated_image[0].reshape(28, 28)\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "\n",
        "X, y = np.meshgrid(x_limit, y_limit)\n",
        "plt.imshow(empty_image, origin = 'upper', cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl7_90x_Ccai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}