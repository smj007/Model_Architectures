{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capsule Network - PyTorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIyx7xUcMfa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "82b01a6b-0101-4e8d-9baa-40c9ded7040d"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "459_LU3ZNUR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms "
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jHoeorJN-5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, dataset, batch_size):\n",
        "    super(Dataset, self).__init__()\n",
        "\n",
        "    if dataset == 'mnist':\n",
        "      dataset_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307, ), (0.3081, ))\n",
        "      ])\n",
        "\n",
        "\n",
        "      train_dataset = datasets.MNIST('/data/mnist', train = True, download = True,\n",
        "                                     transform = dataset_transform)\n",
        "      \n",
        "      test_dataset = datasets.MNIST('/data/mnist', train = False, download = True,\n",
        "                                    transform = dataset_transform)\n",
        "      \n",
        "      self.load_train = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle = True)\n",
        "      self.load_test = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle = False)\n",
        "\n",
        "\n",
        "    elif dataset == 'cifar10':\n",
        "      dataset_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "      ])\n",
        "\n",
        "\n",
        "      train_dataset = datasets.CIFAR10('/data/cifar', train = True, download = True,\n",
        "                                     transform = dataset_transform)\n",
        "      \n",
        "      test_dataset = datasets.CIFAR10('/data/cifar', train = False, download = True,\n",
        "                                    transform = dataset_transform)\n",
        "      \n",
        "      self.load_train = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle = True)\n",
        "      self.load_test = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle = False)\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPV2vKTQRtfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Capsule Net architecture\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "USE_CUDA = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYUJNrjUVLwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "  def __init__(self, in_channels = 1, out_channels = 256, kernel_size = 9):\n",
        "    super(ConvLayer, self).__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels= in_channels,\n",
        "                          out_channels = out_channels,\n",
        "                          kernel_size = kernel_size,\n",
        "                          stride = 1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return F.relu(self.conv(x))  "
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNo5eGIqW6bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "  def __init__(self, num_capsules = 8, in_channels = 256, out_channels = 32, kernel_size = 9, num_routes = 32 * 6 * 6):\n",
        "    super(PrimaryCaps, self).__init__()\n",
        "    self.num_routes = num_routes\n",
        "    self.capsules = nn.ModuleList([\n",
        "                    nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
        "                              kernel_size=kernel_size, stride = 2, padding = 0)\n",
        "                    for _ in range(num_capsules)])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    u = [capsule(x) for capsule in self.capsules]\n",
        "    u = torch.stack(u, dim = 1)\n",
        "    u = u.view(x.size(0), self.num_routes, -1)\n",
        "    u = self.squash(u)\n",
        "    return u\n",
        "\n",
        "\n",
        "  def squash(self, in_tensor):\n",
        "    sq_norm = (in_tensor ** 2).sum(-1, keepdim = True)\n",
        "    output_tensor = sq_norm * in_tensor / ((1 + sq_norm) * torch.sqrt(sq_norm))\n",
        "    return output_tensor"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpRNn-oWZReC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DigitCaps(nn.Module):\n",
        "  def __init__(self, num_capsules = 10, num_routes = 6 * 6 * 32, in_channels = 8, out_channels = 16):\n",
        "    super(DigitCaps, self).__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.num_capsules = num_capsules\n",
        "    self.num_routes = num_routes\n",
        "\n",
        "    self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size(0)\n",
        "    x = torch.stack([x] * self.num_capsules, dim = 2).unsqueeze(4)\n",
        "    W = torch.cat([self.W] * batch_size, dim = 0)\n",
        "    u_hat = torch.matmul(W, x)\n",
        "\n",
        "    #following the routing algorithm\n",
        "    b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
        "    if USE_CUDA: \n",
        "      b_ij = b_ij.cuda()\n",
        "\n",
        "    n_iterations = 3\n",
        "    for iteration in range(n_iterations):\n",
        "      c_ij = F.softmax(b_ij, dim = 1)\n",
        "      c_ij = torch.cat([c_ij] * batch_size, dim = 0).unsqueeze(4)\n",
        "      s_j = (c_ij * u_hat).sum(dim = 1, keepdim = True)\n",
        "      v_j = self.squash(s_j)\n",
        "\n",
        "      #this is to find similarity of v and u_hat, larger sim gets larger routing coefficient\n",
        "      if iteration < n_iterations - 1:\n",
        "        a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim = 1)) \n",
        "        b_ij = b_ij + a_ij.squeeze(4).mean(dim = 0, keepdim = True)\n",
        "\n",
        "    return v_j    \n",
        "\n",
        "  def squash(self, in_tensor):\n",
        "    sq_norm = (in_tensor ** 2).sum(-1, keepdim = True)\n",
        "    output_tensor = sq_norm * in_tensor / ((1 + sq_norm) * torch.sqrt(sq_norm))\n",
        "    return output_tensor"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rqlwTqWZRZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, w = 28, h = 28, channels = 1):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.w = w\n",
        "    self.h = h\n",
        "    self.channels = channels\n",
        "\n",
        "    self.reconstruction_layers = nn.Sequential(\n",
        "        nn.Linear(16 * 10, 512),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Linear(512, 1024),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Linear(1024, self.w * self.h * self.channels),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x, data):\n",
        "      classes = torch.sqrt((x**2).sum(2)) #sum along the samples for each digit prediction (assume parallel Digit caps layers with >1 data)\n",
        "      classes = F.softmax(classes, dim = 0)\n",
        "\n",
        "      _, max_len_idx = classes.max(dim = 1)\n",
        "      masked = Variable(torch.sparse.torch.eye(10))\n",
        "      if USE_CUDA : \n",
        "        masked = masked.to('cuda:0')\n",
        "\n",
        "      print(max_len_idx.squeeze(1).data.shape)\n",
        "      masked = masked.index_select(dim = 0, index = Variable(max_len_idx.squeeze(1).data))\n",
        "      x_in = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
        "      recons = self.reconstruction_layers(x_in)\n",
        "      recons = recons.view(-1, self.channels, self.w, self.h)\n",
        "      return recons, masked  "
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41QPkCh2oKRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "    def __init__(self, config=None):\n",
        "        super(CapsNet, self).__init__()\n",
        "        if config:\n",
        "          self.conv_layer = ConvLayer(config.cnn_in_channels, config.cnn_out_channels,\n",
        "                                      config.cnn_kernel_size)\n",
        "          \n",
        "          self.primary_caps = PrimaryCaps(config.pc_num_capsules, config.pc_in_channels, \n",
        "                                          config.pc_out_channels, config.pc_kernel_size, config.pc_num_routes)\n",
        "          \n",
        "          self.digit_caps = DigitCaps(config.dc_num_capsules, config.dc_num_routes, config.dc_in_channels,\n",
        "                                      config.dc_out_channels)\n",
        "          \n",
        "          self.decoder = Decoder(config.input_width, config.input_height, config.cnn_in_channels)\n",
        "\n",
        "        else:\n",
        "\n",
        "          self.conv_layer = ConvLayer()  \n",
        "          self.primary_caps = PrimaryCaps()  \n",
        "          self.digit_caps = DigitCaps()  \n",
        "          self.decoder = Decoder()\n",
        "\n",
        "\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "      out = self.digit_caps(self.primary_caps(self.conv_layer(data)))\n",
        "      recons, masked = self.decoder(out, data)\n",
        "      return out, recons, masked\n",
        "\n",
        "    def loss(self, data, x, target, recons):\n",
        "      loss_total = self.margin_loss(x, target) + self.recons_loss(data, recons)\n",
        "      return loss_total\n",
        "\n",
        "    def margin_loss(self, x, labels, size_avg = True):\n",
        "      batch_size = x.size(0)\n",
        "      v_c = torch.sqrt((x ** 2).sum(dim = 2, keepdim = True))\n",
        "\n",
        "      left_term = F.relu(0.9 - v_c).view(batch_size, -1)  \n",
        "      right_term = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "\n",
        "      loss = labels * left_term + (1 - labels) * right_term * 0.5\n",
        "      loss = loss.sum(dim = 1, keepdim = True)\n",
        "\n",
        "      return loss  \n",
        "\n",
        "    def recons_loss(self, data, recons):\n",
        "      loss = self.mse_loss(recons.view(recons.size(0), -1), data.view(recons.size(0), -1))  \n",
        "      lambd = 0.0005\n",
        "      return lambd * loss\n"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy_1GMQg8c7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test phase\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm  "
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If7qpZyL8ulX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_CUDA = True if torch.cuda.is_available() else False\n",
        "batch_size = 100\n",
        "n_epochs = 25\n",
        "lr = 0.01\n",
        "momentum = 0.9"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_rwE7D-9Ry2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#config class is an easy way to access all the params of the dataset\n",
        "\n",
        "class Config:\n",
        "\n",
        "  def __init__(self, dataset = 'mnist'):\n",
        "        if dataset == 'mnist':\n",
        "            self.cnn_in_channels = 1\n",
        "            self.cnn_out_channels = 256\n",
        "            self.cnn_kernel_size = 9\n",
        "\n",
        "            # Primary Capsule (pc)\n",
        "            self.pc_num_capsules = 8\n",
        "            self.pc_in_channels = 256\n",
        "            self.pc_out_channels = 32\n",
        "            self.pc_kernel_size = 9\n",
        "            self.pc_num_routes = 32 * 6 * 6\n",
        "\n",
        "            # Digit Capsule (dc)\n",
        "            self.dc_num_capsules = 10\n",
        "            self.dc_num_routes = 32 * 6 * 6\n",
        "            self.dc_in_channels = 8\n",
        "            self.dc_out_channels = 16\n",
        "\n",
        "            # Decoder\n",
        "            self.input_width = 28\n",
        "            self.input_height = 28\n",
        "\n",
        "        elif dataset == 'cifar10':\n",
        "            # CNN (cnn)\n",
        "            self.cnn_in_channels = 3\n",
        "            self.cnn_out_channels = 256\n",
        "            self.cnn_kernel_size = 9\n",
        "\n",
        "            # Primary Capsule (pc)\n",
        "            self.pc_num_capsules = 8\n",
        "            self.pc_in_channels = 256\n",
        "            self.pc_out_channels = 32\n",
        "            self.pc_kernel_size = 9\n",
        "            self.pc_num_routes = 32 * 8 * 8\n",
        "\n",
        "            # Digit Capsule (dc)\n",
        "            self.dc_num_capsules = 10\n",
        "            self.dc_num_routes = 32 * 8 * 8\n",
        "            self.dc_in_channels = 8\n",
        "            self.dc_out_channels = 16\n",
        "\n",
        "            # Decoder\n",
        "            self.input_width = 32\n",
        "            self.input_height = 32      "
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AgJ_65WCs_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, load_train, epoch):\n",
        "    capsule_nw = model\n",
        "    capsule_nw.train()\n",
        "    num_batch = len(list(enumerate(load_train)))\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(load_train)):\n",
        "\n",
        "      target = torch.sparse.torch.eye(10).index_select(dim = 0, index = target)\n",
        "      data, target = Variable(data), Variable(target)\n",
        "\n",
        "      if USE_CUDA:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output, recons, masked = capsule_nw(data)\n",
        "      loss = capsule_nw.loss(data, output, target, recons)  \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
        "      train_loss = loss.item()\n",
        "      total_loss += train_loss\n",
        "\n",
        "      if batch_idx % 100 == 0:\n",
        "        tqdm.write(\"Epoch: [{}/{}], BatchNo: [{}/{}], train_accuracy: {:.6f}, loss: {:.6f}\".format(\n",
        "            epoch,\n",
        "            n_epochs, \n",
        "            batch_idx + 1,\n",
        "            num_batch,\n",
        "            correct / float(batch_size),\n",
        "            train_loss / float(batch_size)\n",
        "        ))\n",
        "\n",
        "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch, n_epochs,\n",
        "                                                          total_loss / len(load_train.dataset))) "
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrs-Us9uMZBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, load_test, epoch):\n",
        "  capsule_nw = model\n",
        "  capsule_nw.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(load_test):\n",
        "\n",
        "    target = torch.sparse.torch.eye(10).index_select(dim = 0, index = target)\n",
        "    data, target = Variable(data), Variable(target)\n",
        "\n",
        "    if USE_CUDA:\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "\n",
        "    output, recons, masked = capsule_nw(data)\n",
        "    loss = capsule_nw.loss(data, output, target, recons)  \n",
        "    \n",
        "    test_loss += loss.item()\n",
        "    correct += sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
        "  \n",
        "  tqdm.write('Epoch: [{}/{}], test loss: {:.6f}'.format(epoch, n_epochs,\n",
        "                                                         test_loss / len(load_test))) "
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5ndvRHs-k8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "bb73fa16-7483-4cf2-b5f4-dcc97f274ce7"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  torch.manual_seed(1)\n",
        "  dataset = 'mnist'\n",
        "  config = Config(dataset)\n",
        "  mnist = Dataset(dataset, batch_size)\n",
        "\n",
        "  capsule_network = CapsNet(config)\n",
        "  capsule_network = torch.nn.DataParallel(capsule_network)\n",
        "\n",
        "  if USE_CUDA:\n",
        "    capsule_network = capsule_network.cuda()\n",
        "  capsule_network = capsule_network.module  \n",
        "\n",
        "  optimizer = torch.optim.Adam(capsule_network.parameters())\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    train(capsule_network, optimizer, mnist.load_train, i)\n",
        "    test(capsule_network, mnist.load_test, i)\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/600 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 16, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-172-832f6b213f5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-170-f2262b1ceaa6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, load_train, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_nw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_nw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-166-a6b82100a22f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigit_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mrecons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-165-c050c7edfe71>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 3: Index is supposed to be an empty tensor or a vector at /pytorch/aten/src/THC/generic/THCTensorIndex.cu:419"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvu9O9iIiRiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}