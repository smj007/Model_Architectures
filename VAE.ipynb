{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-UxoE2DbDXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpToAjWXhQP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPmpATNMYR-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "database = input_data.read_data_sets('/content/data', one_hot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iThJSC2v0qQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001\n",
        "epochs = 30000\n",
        "batch_size = 32\n",
        "image_dimension = 784\n",
        "neural_network_dimension = 512 #for the hidden layer\n",
        "latent_variable_dimension = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a89iKTL404iZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier(in_shape):\n",
        "  val = tf.random_normal(shape = in_shape, stddev = 1./tf.sqrt(in_shape[0]/2.))\n",
        "  return val"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC1BKMIg0sBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #weight dict\n",
        "\n",
        " Weight = {\n",
        "     \"weight_matrix_encoder_hidden\": tf.Variable(xavier([image_dimension, neural_network_dimension])),\n",
        "     \"weight_mean_hidden\": tf.Variable(xavier([neural_network_dimension, latent_variable_dimension])),\n",
        "     \"weight_std_hidden\": tf.Variable(xavier([neural_network_dimension, latent_variable_dimension])),\n",
        "     \"weight_matrix_decoder_hidden\": tf.Variable(xavier([latent_variable_dimension, neural_network_dimension])),\n",
        "     \"weight_decoder\": tf.Variable(xavier([neural_network_dimension, image_dimension]))\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vYCVhk0177C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Bias = {\n",
        "     \"bias_matrix_encoder_hidden\": tf.Variable(xavier([neural_network_dimension])),\n",
        "     \"bias_mean_hidden\": tf.Variable(xavier([latent_variable_dimension])),\n",
        "     \"bias_std_hidden\": tf.Variable(xavier([latent_variable_dimension])),\n",
        "     \"bias_matrix_decoder_hidden\": tf.Variable(xavier([neural_network_dimension])),\n",
        "     \"bias_decoder\": tf.Variable(xavier([image_dimension]))\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFi3VA7s2ZuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#computational graph\n",
        "\n",
        "#Encoder\n",
        "\n",
        "image_X = tf.placeholder(tf.float32, shape = [None, image_dimension])\n",
        "\n",
        "Encoder_layer = tf.add(tf.matmul(image_X, Weight['weight_matrix_encoder_hidden']), Bias['bias_matrix_encoder_hidden'])\n",
        "Encoder_layer = tf.nn.tanh(Encoder_layer)\n",
        "\n",
        "Mean_layer = tf.add(tf.matmul(Encoder_layer, Weight['weight_mean_hidden']), Bias['bias_mean_hidden'])\n",
        "Standard_deviation_layer = tf.add(tf.matmul(Encoder_layer, Weight['weight_std_hidden']), Bias['bias_std_hidden']) \n",
        "\n",
        "\n",
        "epsilon = tf.random_normal(tf.shape(Standard_deviation_layer), dtype = tf.float32, mean = 0.0, stddev = 1.0)\n",
        "latent_layer = Mean_layer + tf.exp(0.5 * Standard_deviation_layer) * epsilon  #this is a numerical stability move\n",
        "\n",
        "Decoder_hidden = tf.add(tf.matmul(latent_layer, Weight['weight_matrix_decoder_hidden']), Bias['bias_matrix_decoder_hidden'])\n",
        "Decoder_hidden = tf.nn.tanh(Decoder_hidden)\n",
        "\n",
        "Decoder_output_layer = tf.add(tf.matmul(Decoder_hidden, Weight['weight_decoder']), Bias['bias_decoder'])\n",
        "Decoder_output_layer = tf.nn.sigmoid(Decoder_output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Vuj6N2MTVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def loss_function(original_image, reconstructed_image):\n",
        "\n",
        "   data_fidelity_loss = original_image * tf.log(1e-10 + reconstructed_image) + (1 - original_image) * tf.log(1e-10 + 1 - reconstructed_image)\n",
        "   data_fidelity_loss = -tf.reduce_sum(data_fidelity_loss, 1)\n",
        "\n",
        "   KL_div_loss = 1 + Standard_deviation_layer - tf.square(Mean_layer) - tf.exp(Standard_deviation_layer)\n",
        "   KL_div_loss = -0.5 * tf.reduce_sum(KL_div_loss, 1)\n",
        "\n",
        "   #weight for each case possible\n",
        "   alpha = 1\n",
        "   beta = 1\n",
        "   network_loss = tf.reduce_mean(alpha * data_fidelity_loss + beta * KL_div_loss)\n",
        "   return network_loss\n",
        "\n",
        " loss_value = loss_function(image_X, Decoder_output_layer)\n",
        " optimizer = tf.train.RMSPropOptimizer(lr).minimize(loss_value)\n",
        "\n",
        " init = tf.global_variables_initializer()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEc4UU1ZQWHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "for i in range(epochs):\n",
        "  x_batch, _ = database.train.next_batch(batch_size)\n",
        "  _, loss = sess.run([optimizer, loss_value], feed_dict = {image_X : x_batch})\n",
        "  if i%5000 == 0:\n",
        "    print('Loss is {0} at iteration {1}'.format(loss, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcFllI0yQV7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing phase - test only generator to sample the data from the distn but a new sample\n",
        "\n",
        " noise_X = tf.placeholder(tf.float32, shape = [None, latent_variable_dimension])\n",
        "\n",
        " #generative model testing\n",
        "\n",
        "Decoder_hidden = tf.add(tf.matmul(noise_X, Weight['weight_matrix_decoder_hidden']), Bias['bias_matrix_decoder_hidden'])\n",
        "Decoder_hidden = tf.nn.tanh(Decoder_hidden)\n",
        "\n",
        "Decoder_output_layer = tf.add(tf.matmul(Decoder_hidden, Weight['weight_decoder']), Bias['bias_decoder'])\n",
        "Decoder_output_layer = tf.nn.sigmoid(Decoder_output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKIa4Mtjd1nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualising the output obtained ----\n",
        "\n",
        "n = 20 #the grid dim\n",
        "x_limit = np.linspace(-2, 2, n)\n",
        "y_limit = np.linspace(-2, 2, n)\n",
        "empty_image = np.empty((28*n, 28*n))\n",
        "\n",
        "for i, zi in enumerate(x_limit):\n",
        "  for j, pi in enumerate(y_limit):\n",
        "    generated_latent_layer = np.array([[zi, pi]]*batch_size) #images fed as input\n",
        "    #generated_latent_layer = np.random.normal(0, 1, size = [batch_size, latent_variable_dimension])\n",
        "    generated_image  = sess.run(Decoder_output_layer, feed_dict = {noise_X : generated_latent_layer})\n",
        "    empty_image[(n-1-i)*28 : (n-i)*28, j*28 : (j+1)*28] = generated_image[0].reshape(28, 28)\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "\n",
        "X, y = np.meshgrid(x_limit, y_limit)\n",
        "plt.imshow(empty_image, origin = 'upper', cmap = 'gray')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}